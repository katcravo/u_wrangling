{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = 'osm/sample.osm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened_file\n",
      "{'member': 31,\n",
      " 'nd': 11796,\n",
      " 'node': 9413,\n",
      " 'osm': 1,\n",
      " 'relation': 8,\n",
      " 'tag': 8828,\n",
      " 'way': 1539}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    osm_file = open(filename, \"r\")\n",
    "    print ('opened_file')\n",
    "    tagsdict = defaultdict (lambda: 0)\n",
    "    #for event, elem in ET.iterparse(osm_file, events=('start', )):\n",
    "    #    tagsdict[elem.tag]=tagsdict[elem.tag]+1\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end':\n",
    "            tagsdict[elem.tag]=tagsdict[elem.tag]+1\n",
    "            root.clear()    \n",
    " \n",
    "    return dict(tagsdict)\n",
    "\n",
    "tags = count_tags(filename)\n",
    "pprint.pprint(tags)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 31,\n",
      " 'nd': 11796,\n",
      " 'node': 9413,\n",
      " 'osm': 1,\n",
      " 'relation': 8,\n",
      " 'tag': 8828,\n",
      " 'way': 1539}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Get a list of all the tags and their count\n",
    "\"\"\"\n",
    "\n",
    "def count_tags(filename):\n",
    "    osm_file = open(filename, \"r\")\n",
    "    tagsdict = defaultdict (lambda: 0)\n",
    "    for event, elem in ET.iterparse(osm_file, events=('start', )):\n",
    "        tagsdict[elem.tag]=tagsdict[elem.tag]+1\n",
    "    return dict(tagsdict)\n",
    "\n",
    "tags = count_tags(filename)\n",
    "pprint.pprint(tags)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 3452, 'lower_colon': 5243, 'other': 106, 'problemchars': 27}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "check that the tag keys are valid chars\n",
    "\"\"\"\n",
    "import re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "\n",
    "\n",
    "osm_file = open(filename, \"r\")\n",
    "context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "_, root = next(context)\n",
    "for event, element in context:\n",
    "    if event == 'end':\n",
    "        if element.tag == \"tag\":\n",
    "            key = element.attrib['k']\n",
    "            whichCase = \"other\"\n",
    "            if (lower.match(key)): whichCase = \"lower\"\n",
    "            elif (lower_colon.match(key)): whichCase = \"lower_colon\"\n",
    "            elif (problemchars.search(key)): whichCase = \"problemchars\"\n",
    "            #print key, whichCase\n",
    "            keys [whichCase] = keys [whichCase] + 1\n",
    "    root.clear()\n",
    "    \n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['1248',\n",
      "     '1HealthPlz',\n",
      "     '3yoda',\n",
      "     '42429',\n",
      "     'ALE!',\n",
      "     'Aaron Lidman',\n",
      "     'Abeer2015',\n",
      "     'Alanna Smith',\n",
      "     'AlexTheTux',\n",
      "     'Andre Engels',\n",
      "     'Andre68',\n",
      "     'Anthony Moffa',\n",
      "     'Arboreal',\n",
      "     'Arcadium',\n",
      "     'BMM994',\n",
      "     u'BlaueBl\\xfcte',\n",
      "     'Bow717588',\n",
      "     'Brett Camper',\n",
      "     'Bri Hendriksen',\n",
      "     'CS9229',\n",
      "     'CaptainCrunch',\n",
      "     'Cato_d_Ae',\n",
      "     'Chris Parker',\n",
      "     'ChrisZontine',\n",
      "     'Chrisi_LE',\n",
      "     'Christian70',\n",
      "     'Christoph Lotz',\n",
      "     'CitymapperHQ',\n",
      "     'ColinReilly',\n",
      "     'Constable',\n",
      "     'CoreyFarwell',\n",
      "     'Craig Williams',\n",
      "     'Dami_Tn',\n",
      "     'DanX',\n",
      "     'DaveHansenTiger',\n",
      "     'DawsZed',\n",
      "     'DeVietor',\n",
      "     'DennisL',\n",
      "     'DerRote',\n",
      "     'Derick Rethans',\n",
      "     'Dirk Lohse',\n",
      "     'Easky30',\n",
      "     'Edward',\n",
      "     'Eliyak',\n",
      "     'ElliottPlack',\n",
      "     'Eric Godwin',\n",
      "     'Ericles',\n",
      "     'Extramiler',\n",
      "     'FitmanNJ',\n",
      "     'Fluous',\n",
      "     'GISJoe',\n",
      "     'GaryS5',\n",
      "     'Geofreund1',\n",
      "     'Geogast',\n",
      "     'GinosNY',\n",
      "     'HPNPilot',\n",
      "     'Haggador Sparticus',\n",
      "     'Helmchen42',\n",
      "     'Helpist',\n",
      "     'Howpper',\n",
      "     u'Humbleb\\xe6k1984',\n",
      "     'IanH',\n",
      "     'InetSoftTech',\n",
      "     'Irunongames',\n",
      "     'JDCase',\n",
      "     'JGregory',\n",
      "     'J_Hutch',\n",
      "     'JaLooNz',\n",
      "     'Jaiy',\n",
      "     'Jason Wray',\n",
      "     'JessAk71',\n",
      "     'JimmyRocks',\n",
      "     'Joe Rosol',\n",
      "     'JoeMapNY',\n",
      "     'John Peterson',\n",
      "     'JosClag',\n",
      "     'JuPr',\n",
      "     'KindredCoda',\n",
      "     u'Kom\\u044fpa',\n",
      "     'Korzun',\n",
      "     'KristenK',\n",
      "     'Kyzersawsay',\n",
      "     'Latze',\n",
      "     'LizBarry_nycbuildings',\n",
      "     'LucasLarson',\n",
      "     'Luis36995',\n",
      "     'MCM7',\n",
      "     'MaZderMind',\n",
      "     'Map Corrections',\n",
      "     'MapDuck',\n",
      "     'MarcelHerault',\n",
      "     'Mark Gray',\n",
      "     'Markod80',\n",
      "     'Masha Schneider',\n",
      "     'Maskulinum',\n",
      "     'Matt1993',\n",
      "     'Memoire',\n",
      "     'Mhosni',\n",
      "     'Michael Yap',\n",
      "     'Michael_C_',\n",
      "     'Mikelatham',\n",
      "     'MilaZ',\n",
      "     'MineHillJay',\n",
      "     'Moose1',\n",
      "     'MxxCon',\n",
      "     'NE2',\n",
      "     'NJDataUploads',\n",
      "     'NateOMatic',\n",
      "     'Neil828',\n",
      "     'Nicolas Love',\n",
      "     'Nikhil K',\n",
      "     'NiteOwlNY',\n",
      "     'NoelB',\n",
      "     'Nordpfeil',\n",
      "     'Nyq',\n",
      "     'OceanVortex',\n",
      "     'Olek Lorenc',\n",
      "     'Omnific',\n",
      "     'Patrick Brown',\n",
      "     'Paul Johnson',\n",
      "     'Pepper',\n",
      "     'PeterEastern',\n",
      "     'PhillyBiker',\n",
      "     'Picholeiro',\n",
      "     'PlaneMad',\n",
      "     'Pnrrth',\n",
      "     'RabidManatee',\n",
      "     'Raj Singh',\n",
      "     'RichRico',\n",
      "     'Richard Symonds',\n",
      "     'Rickyrab1',\n",
      "     'Roadrunner21',\n",
      "     'Rub21',\n",
      "     'Rub21_nycbuildings',\n",
      "     'RussNelson',\n",
      "     'SH17',\n",
      "     'SP!KE',\n",
      "     'S_H',\n",
      "     'SarahHaskins',\n",
      "     'SarahHaskins_nycbuildings',\n",
      "     'SarnXero',\n",
      "     'Sarr_Cat',\n",
      "     'Seandebasti',\n",
      "     'Shawnee Gundry',\n",
      "     'Sim_nycbuildings',\n",
      "     'Skipper3210',\n",
      "     'Some_Person',\n",
      "     'Spitfire24',\n",
      "     'StellanL',\n",
      "     'SteveDorries',\n",
      "     'Strider55',\n",
      "     'TIGERcnl',\n",
      "     'Telemain',\n",
      "     'The Maarssen Mapper',\n",
      "     'Theodin',\n",
      "     'Thita',\n",
      "     'Tiberia99',\n",
      "     'TimmyLittle',\n",
      "     'ToeBee',\n",
      "     'Tomash Pilshchik',\n",
      "     'Trex2001',\n",
      "     'Tronikon',\n",
      "     'Umbugbene',\n",
      "     'WK95',\n",
      "     'WestsideGuy',\n",
      "     'WorldWander',\n",
      "     'Xapitoun',\n",
      "     'Xoan Manuel',\n",
      "     'YamaOfParadise',\n",
      "     'ZekeFarwell',\n",
      "     'aalox',\n",
      "     'aaron_nycbuildings',\n",
      "     'aarp65',\n",
      "     'abel801',\n",
      "     'afdreher',\n",
      "     'aguy0523',\n",
      "     'airlifter',\n",
      "     'aisaksen',\n",
      "     'ajashton',\n",
      "     'akiuehaha',\n",
      "     'amillar',\n",
      "     'amurdock',\n",
      "     'andrewpmk',\n",
      "     'andrzej85',\n",
      "     'anthonyd969',\n",
      "     'applejax16',\n",
      "     'apwright_nycbuildings',\n",
      "     'ar2082',\n",
      "     'bass',\n",
      "     'bdiscoe',\n",
      "     'beweta',\n",
      "     'bhousel',\n",
      "     'bjimba',\n",
      "     'bjoern262',\n",
      "     'bot-mode',\n",
      "     'brianegge',\n",
      "     'calfarome',\n",
      "     'celosia_nycbuildings',\n",
      "     'ceyockey',\n",
      "     'chdr',\n",
      "     'choess',\n",
      "     'chris2112',\n",
      "     'chrismcnally',\n",
      "     'chrismcnally_nycbuildings',\n",
      "     'cityracks',\n",
      "     'cl94',\n",
      "     'claysmalley',\n",
      "     'cmif4',\n",
      "     'coleman',\n",
      "     'cquest',\n",
      "     'creed1965',\n",
      "     'crystalwalrein',\n",
      "     'daniel felipe',\n",
      "     'daniel_solow',\n",
      "     'daniel_sz',\n",
      "     'dannykath',\n",
      "     'davidearl',\n",
      "     'dc157',\n",
      "     'dchiles',\n",
      "     'delphiN',\n",
      "     'dhaluza',\n",
      "     'dhetteix',\n",
      "     'dkratzert',\n",
      "     'dloutzen',\n",
      "     'dmgroom_ct',\n",
      "     'dpawlyk',\n",
      "     'dufekin',\n",
      "     'dwh1985',\n",
      "     'ebrelsford',\n",
      "     'ebrelsford_nycbuildings',\n",
      "     'ecaldwell',\n",
      "     'ediyes',\n",
      "     'ediyes_nycbuildings',\n",
      "     'effektz',\n",
      "     'egore911',\n",
      "     'ekolmus_nycbuildings',\n",
      "     'elhide',\n",
      "     'elszd',\n",
      "     'emacsen',\n",
      "     'emacsen_nycbuildings',\n",
      "     'eric22',\n",
      "     'erjiang',\n",
      "     'ethelmermaid',\n",
      "     'ethomas33',\n",
      "     'eugenebata',\n",
      "     'ewedistrict_nycbuildings',\n",
      "     'fiveisalive',\n",
      "     'flierfy',\n",
      "     'fpschmitt',\n",
      "     'fx99',\n",
      "     'gadget',\n",
      "     'gknisely',\n",
      "     'gpesquero',\n",
      "     'greggerm',\n",
      "     'gsteinmon',\n",
      "     'gtluke',\n",
      "     'heatonjames',\n",
      "     'hmoskowitz',\n",
      "     'hno2',\n",
      "     'holub',\n",
      "     'homeslice60148',\n",
      "     'howdystranger',\n",
      "     'iamkrzys',\n",
      "     'iandees',\n",
      "     'ifrontado',\n",
      "     'infinitesunrise',\n",
      "     'ingalls',\n",
      "     'ingalls_nycbuildings',\n",
      "     'jakepg1',\n",
      "     'jengelb1',\n",
      "     'jeremyb_nycbuildings',\n",
      "     'jfeath49',\n",
      "     'jlafaso',\n",
      "     'jlert_nycbuildings',\n",
      "     'johnjreiser',\n",
      "     'jptitanic13',\n",
      "     'jqr',\n",
      "     'jtorraca',\n",
      "     'jtvandyk',\n",
      "     'jzamanski',\n",
      "     'karitotp',\n",
      "     'ke9tv',\n",
      "     'ke9tv-nysdec-lands',\n",
      "     'kharri1073',\n",
      "     'kreilly',\n",
      "     'kriscarle',\n",
      "     'lilywong',\n",
      "     'lizard657',\n",
      "     'ljjwfr',\n",
      "     'lothisoft',\n",
      "     'louie_nycbuildings',\n",
      "     'luiswoo',\n",
      "     'lxbarth',\n",
      "     'lxbarth_nycbuildings',\n",
      "     'majormajor42',\n",
      "     'manman222',\n",
      "     'mapping15',\n",
      "     'marek kleciak',\n",
      "     'mario824',\n",
      "     'maxerickson',\n",
      "     'mdroads',\n",
      "     'merll431',\n",
      "     'mike sk',\n",
      "     'mikercpc',\n",
      "     'mikeybonez28',\n",
      "     'miluethi',\n",
      "     'minewman',\n",
      "     'misabrzi',\n",
      "     'mlc',\n",
      "     'momo737',\n",
      "     'monkeyrobot',\n",
      "     'mwexler',\n",
      "     'navimont_nycbuildings',\n",
      "     'neuralmarket',\n",
      "     'nfgusedautoparts',\n",
      "     'nkhall',\n",
      "     'oini',\n",
      "     'oldtopos',\n",
      "     'onurozgun',\n",
      "     'orcl_99',\n",
      "     'osmmaker',\n",
      "     'owly',\n",
      "     'pagibson',\n",
      "     'pathym',\n",
      "     'paulmach',\n",
      "     'peace2',\n",
      "     'pnorman',\n",
      "     'pundit_traveller',\n",
      "     'qaz668',\n",
      "     'quarkatron',\n",
      "     'rad1ance',\n",
      "     'redsteakraw',\n",
      "     'ridixcr',\n",
      "     'riordabr',\n",
      "     'rjhale1971',\n",
      "     'rkcarolan16',\n",
      "     'robgeb',\n",
      "     'rutgers_oss',\n",
      "     'ruthmaben',\n",
      "     'ryan8227',\n",
      "     'saikofish',\n",
      "     'saldiccio',\n",
      "     'samely',\n",
      "     'samlibby',\n",
      "     'sbook',\n",
      "     'scep',\n",
      "     'shvrm',\n",
      "     'skwidbreth',\n",
      "     'slashme',\n",
      "     'smlevine',\n",
      "     'softex',\n",
      "     'srividya_c',\n",
      "     'stefpap',\n",
      "     'stevea',\n",
      "     'steverumizen',\n",
      "     'svance92',\n",
      "     'talexhv',\n",
      "     'taskswap',\n",
      "     'tf66',\n",
      "     'thetornado76',\n",
      "     'threeyoda',\n",
      "     'tnsinclass',\n",
      "     'tomasCY',\n",
      "     'tylerchill',\n",
      "     'tyos',\n",
      "     'ubuka0',\n",
      "     'user_5359',\n",
      "     'user_963517',\n",
      "     'vaandor',\n",
      "     'vincent_95',\n",
      "     'wambag',\n",
      "     'watame',\n",
      "     'will l',\n",
      "     'will-i-am',\n",
      "     'woodpeck_fixbot',\n",
      "     'xybot',\n",
      "     'zingbot_nycbuildings',\n",
      "     u'\\u0421\\u0435\\u043c\\u0451\\u043d \\u0421\\u0435\\u043c\\u0451\\u043d\\u043e\\u0432',\n",
      "     u'\\u042e\\u043a\\u0430\\u0442\\u0430\\u043d'])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "get the unique users that have modified the map\n",
    "\"\"\"\n",
    "\n",
    "def get_attrib(element, key):\n",
    "    if ( key in element.attrib ):\n",
    "        return element.attrib[key]\n",
    "    return None\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user  = get_attrib(element, 'user')\n",
    "        if user != None: users.add(user)\n",
    "    return users\n",
    "\n",
    "users = process_map(filename)\n",
    "pprint.pprint(users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bowery': set(['Bowery']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'East': set(['Aqueduct Avenue East',\n",
      "              'Van Wyck Expressway Service Road East']),\n",
      " 'Green': set(['Dover Green']),\n",
      " 'Island': set(['Randalls Island']),\n",
      " 'North': set(['Mayfair Drive North']),\n",
      " 'Rd': set(['Knightsbridge Rd']),\n",
      " 'South': set(['Andrews Ave South',\n",
      "               'Horace Harding Expressway Service Road South']),\n",
      " 'West': set(['Central Park West',\n",
      "              'Clearview Expressway Service Road West',\n",
      "              'Prospect Park West',\n",
      "              'Van Wyck Expressway Service Road West'])}\n",
      "Has a valid suffix  Mayfair Drive North\n",
      "Mayfair Drive North => Mayfair Drive North\n",
      "Has a valid suffix  Central Park West\n",
      "Central Park West => Central Park West\n",
      "Has a valid suffix  Van Wyck Expressway Service Road West\n",
      "Van Wyck Expressway Service Road West => Van Wyck Expressway Service Road West\n",
      "Has a valid suffix  Clearview Expressway Service Road West\n",
      "Clearview Expressway Service Road West => Clearview Expressway Service Road West\n",
      "Has a valid suffix  Prospect Park West\n",
      "Prospect Park West => Prospect Park West\n",
      "Bowery => Bowery\n",
      "Fixing name  Knightsbridge Rd\n",
      "Knightsbridge Rd => Knightsbridge Road\n",
      "Dover Green => Dover Green\n",
      "Randalls Island => Randalls Island\n",
      "Broadway => Broadway\n",
      "Has a valid suffix  Aqueduct Avenue East\n",
      "Aqueduct Avenue East => Aqueduct Avenue East\n",
      "Has a valid suffix  Van Wyck Expressway Service Road East\n",
      "Van Wyck Expressway Service Road East => Van Wyck Expressway Service Road East\n",
      "Has a valid suffix  Andrews Ave South\n",
      "Fixing name  Andrews Ave\n",
      "Andrews Ave South => Andrews Avenue South\n",
      "Has a valid suffix  Horace Harding Expressway Service Road South\n",
      "Horace Harding Expressway Service Road South => Horace Harding Expressway Service Road South\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Audit Street Types\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "first_word_re = re.compile(r'^\\w+', re.IGNORECASE)\n",
    "old_expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Terrace\", \"Loop\", \"Highway\", \"Course\", \"Circle\", \"Way\", \"Crescent\", \"Walk\"]\n",
    "expected_first = [\"Avenue\"]\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"Rd\" : \"Road\"\n",
    "            }\n",
    "extra_suffix = [\"North\", \"East\", \"West\", \"South\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            #print 'Found', street_type\n",
    "            if street_type_first(street_name): return\n",
    "            else: street_types[street_type].add(street_name)\n",
    "            \n",
    "def street_type_first(street_name):\n",
    "    #print 'Check first', street_name\n",
    "    m = first_word_re.search(street_name)\n",
    "    if m:\n",
    "        if m.group() in expected_first:\n",
    "            #print 'Found Street Type first for', street_name\n",
    "            return True\n",
    "    return False\n",
    "            \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street_types_in_file(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    #print tag.attrib['k'], tag.attrib['v']\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        \n",
    "        #print \"Checking \", name\n",
    "        if street_type in expected: pass\n",
    "        elif street_type in mapping: \n",
    "            print \"Fixing name \", name\n",
    "            name = street_type_re.sub(mapping[street_type], name)\n",
    "            #print \"Fixed name \", name\n",
    "        else:\n",
    "            processed_suffix = process_suffix(name, mapping)\n",
    "            if processed_suffix != None: return processed_suffix\n",
    "        \n",
    "        return name     \n",
    "\n",
    "def process_suffix (name, mapping):\n",
    "    split_name = name.split(' ')\n",
    "    if len(split_name) > 2 and split_name[-1] in extra_suffix:\n",
    "        print \"Has a valid suffix \", name\n",
    "        return update_name(name.rsplit(' ', 1)[0], mapping) + ' ' + split_name[-1] \n",
    "    return None\n",
    "\n",
    "unexpected_st_types = audit_street_types_in_file(filename)\n",
    "pprint.pprint(dict(unexpected_st_types))\n",
    "\n",
    "for st_type, ways in unexpected_st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, \"=>\", better_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "replace_tags = {'addr':'address'}\n",
    "#has_value_and_children = ['hgv', 'name', 'building', 'railway', 'lanes', 'maxspeed', 'source']\n",
    "has_value_and_children = []\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_tag (name, value, tags, found_complex_tag):\n",
    "    #tags[name]=value\n",
    "    #if (name.startswith('hgv')): print name, value\n",
    "    try:\n",
    "        if (name!= None and len(name)>0 and name.strip()!=':' and \n",
    "            name.strip()!='' and not problemchars.search(name)):\n",
    "            \n",
    "            levels = name.split(':')\n",
    "            \n",
    "            #extract the top level key and convert it as needed\n",
    "            top = levels[0]\n",
    "            top = replace_tags.get(top,top)\n",
    "            \n",
    "            #assign value if it's a top level attribute\n",
    "            if len(levels) == 1: \n",
    "                if top not in tags: tags[top] = value\n",
    "                else: \n",
    "                    print top, value, ' other value already found as ', tags[top]\n",
    "                \n",
    "            #add to address dict if there are two levels\n",
    "            elif top=='address' and len(levels) == 2:\n",
    "                if 'address' not in tags: tags['address']={}                    \n",
    "                if not isinstance(tags['address'],dict): \n",
    "                    print 'address:', name, value, ' overwriting simple value already found as ', tags['address']\n",
    "                    tags['address']={}\n",
    "                process_tag (levels[1],value,tags['address'], found_complex_tag)\n",
    "                \n",
    "            #add to a dict if there are multiple levels\n",
    "            elif top!='address' and len(levels) > 1:\n",
    "                if top in has_value_and_children: top = top + \"_data\"\n",
    "                elif top in tags and not isinstance(tags[top],dict): \n",
    "                    #a root value was already found for this tag.\n",
    "                    print name, value, ' unexpected - simple value already found as ', top, tags[top]\n",
    "                    found_complex_tag.add(top)\n",
    "                    return\n",
    "                if top not in tags: tags[top]={}                    \n",
    "                process_tag (name.split(':', 1)[1], value, tags[top], found_complex_tag)\n",
    "                \n",
    "    except Exception, e:\n",
    "        print \"Failed: %s\" % e\n",
    "        print 'Exception', name, value\n",
    "        pprint.pprint(tags)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_attributes(element):\n",
    "    attributes = {}\n",
    "    created = {}\n",
    "    #address = {}\n",
    "    pos = [None,None]\n",
    "\n",
    "    for attribute in element.attrib:\n",
    "        value = element.attrib[attribute]\n",
    "        #print attribute\n",
    "\n",
    "        if attribute in CREATED:\n",
    "            created[attribute] = value\n",
    "\n",
    "        elif attribute == 'lat': \n",
    "            try:\n",
    "                pos [0] = float(value)\n",
    "            except ValueError:\n",
    "                print \"Not a float\"                \n",
    "        elif attribute == 'lon':\n",
    "            try:\n",
    "                pos [1] = float(value)\n",
    "            except ValueError:\n",
    "                print \"Not a float\"\n",
    "\n",
    "        else: attributes[attribute] = value    \n",
    "\n",
    "    attributes['created'] = created\n",
    "    if None not in pos: attributes['pos'] = pos\n",
    "        \n",
    "    return attributes    \n",
    "\n",
    "def process_refs(element):\n",
    "    node_refs = []\n",
    "    for ref in element.iter(\"nd\"):\n",
    "        node_refs.append(ref.attrib['ref'])\n",
    "    if len(node_refs) > 0 : return {\"node_refs\":node_refs}\n",
    "    return {}\n",
    "\n",
    "def process_tags(element, found_complex_tag):\n",
    "    tags = {}\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        process_tag(tag.attrib['k'],tag.attrib['v'], tags, found_complex_tag)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_tags = ['street']\n",
    "def fix_street(tags):\n",
    "    if 'address' in tags:\n",
    "        addr = tags['address']\n",
    "        for key in addr:\n",
    "            if key in street_tags:\n",
    "                #print 'checking', addr[key]\n",
    "                addr[key] = update_name(addr[key], mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element, found_complex_tag):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node['type']=element.tag        \n",
    "        refs = process_refs(element)\n",
    "        node.update(refs)\n",
    "        attrs = process_attributes(element)    \n",
    "        node.update(attrs)\n",
    "        tags = process_tags(element, found_complex_tag)\n",
    "        fix_street(tags)\n",
    "        node.update(tags)\n",
    "              \n",
    "        #pprint.pprint( node )\n",
    "        return node\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has a valid suffix  Prospect Park West\n",
      "Has a valid suffix  Clearview Expressway Service Road West\n",
      "Has a valid suffix  Andrews Ave South\n",
      "Fixing name  Andrews Ave\n",
      "maxspeed:hgv 50 mph  unexpected - simple value already found as  maxspeed 55 mph\n",
      "maxspeed:goods 50 mph  unexpected - simple value already found as  maxspeed 55 mph\n",
      "hgv:national_network yes  unexpected - simple value already found as  hgv designated\n",
      "hgv:state_network yes  unexpected - simple value already found as  hgv designated\n",
      "Fixing name  Knightsbridge Rd\n",
      "hgv:state_network yes  unexpected - simple value already found as  hgv designated\n",
      "name:en Bakery  unexpected - simple value already found as  name Bakery\n",
      "Has a valid suffix  Mayfair Drive North\n",
      "Has a valid suffix  Horace Harding Expressway Service Road South\n",
      "building:levels 20  unexpected - simple value already found as  building apartments\n",
      "Has a valid suffix  Central Park West\n",
      "Has a valid suffix  Aqueduct Avenue East\n",
      "Has a valid suffix  Van Wyck Expressway Service Road West\n",
      "Has a valid suffix  Van Wyck Expressway Service Road East\n",
      "hgv:state_network yes  unexpected - simple value already found as  hgv designated\n",
      "hgv:state_network yes  unexpected - simple value already found as  hgv designated\n",
      "building:levels 2  unexpected - simple value already found as  building terrace\n",
      "railway:track_ref 10  unexpected - simple value already found as  railway subway\n",
      "building:levels 2  unexpected - simple value already found as  building terrace\n",
      "lanes:forward 4  unexpected - simple value already found as  lanes 7\n",
      "hgv:state_network yes  unexpected - simple value already found as  hgv designated\n",
      "building:levels 6  unexpected - simple value already found as  building yes\n",
      "railway:track_ref 3  unexpected - simple value already found as  railway subway\n",
      "set(['building', 'maxspeed', 'lanes', 'name', 'hgv', 'railway'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse an OSM XML file and call shape_element for each entry,\n",
    "the shaped element is written to a file in json format\n",
    "\"\"\"\n",
    "def check_has_value_and_children(file_in, pretty = False):\n",
    "    #data = []\n",
    "    found_complex_tag = set()\n",
    "    osm_file = open(filename, \"r\")\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end':\n",
    "            el = shape_element(elem, found_complex_tag)\n",
    "        root.clear()\n",
    "    return found_complex_tag\n",
    "print check_has_value_and_children(filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "shape_element() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-cc720e585dbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-cc720e585dbe>\u001b[0m in \u001b[0;36mprocess_map\u001b[1;34m(file_in, pretty)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: shape_element() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "x = process_map(filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has a valid suffix  Prospect Park West\n",
      "Has a valid suffix  Clearview Expressway Service Road West\n",
      "Has a valid suffix  Andrews Ave South\n",
      "Fixing name  Andrews Ave\n",
      "Fixing name  Knightsbridge Rd\n",
      "Has a valid suffix  Mayfair Drive North\n",
      "Has a valid suffix  Horace Harding Expressway Service Road South\n",
      "Has a valid suffix  Central Park West\n",
      "Has a valid suffix  Aqueduct Avenue East\n",
      "Has a valid suffix  Van Wyck Expressway Service Road West\n",
      "Has a valid suffix  Van Wyck Expressway Service Road East\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import json\n",
    "\"\"\"\n",
    "Parse an OSM XML file and call shape_element for each entry,\n",
    "the shaped element is written to a file in json format\n",
    "\"\"\"\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        osm_file = open(filename, \"r\")\n",
    "        context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "        _, root = next(context)\n",
    "        for event, elem in context:\n",
    "            if event == 'end':\n",
    "                el = shape_element(elem)\n",
    "                if el:\n",
    "                    data.append(el)\n",
    "                    if pretty:\n",
    "                        fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                    else:\n",
    "                        fo.write(json.dumps(el) + \"\\n\")\n",
    "            root.clear()\n",
    "    return data\n",
    "\n",
    "x = process_map(filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'both_ways': set([u'lanes_data.both_ways', u'turn.lanes_data.both_ways']),\n",
      " u'colour': set([u'building_data.colour', u'roof.colour']),\n",
      " u'forward': set([u'lanes_data.forward', u'turn.lanes_data.forward']),\n",
      " u'goods': set([u'goods', u'maxspeed_data.goods']),\n",
      " u'height': set([u'height', u'roof.height']),\n",
      " u'hgv': set([u'hgv', u'maxspeed_data.hgv', u'source_data.hgv']),\n",
      " u'id': set([u'gnis.id', u'id']),\n",
      " u'import_uuid': set([u'gnis.import_uuid', u'import_uuid']),\n",
      " u'lanes': set([u'lanes', u'note.lanes', u'turn.lanes']),\n",
      " u'material': set([u'building_data.material', u'material', u'roof.material']),\n",
      " u'national_network': set([u'hgv_data.national_network',\n",
      "                           u'source_data.hgv_data.national_network']),\n",
      " u'old_ref': set([u'old_ref', u'source_data.old_ref']),\n",
      " u'reviewed': set([u'gnis.reviewed', u'tiger.reviewed']),\n",
      " u'source': set([u'generator.source', u'source', u'tiger.source']),\n",
      " u'state_network': set([u'hgv_data.state_network',\n",
      "                        u'source_data.hgv_data.state_network']),\n",
      " u'type': set([u'generator.type', u'type'])}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_tags(node,parent,tags):\n",
    "    for key in node:\n",
    "        #print key, node[key]\n",
    "        if isinstance (node[key],dict): \n",
    "            #print \"found dict for \", key\n",
    "            extract_tags(node[key] , parent + key + \".\", tags)\n",
    "        else:\n",
    "            if key not in tags: tags[key] = set()\n",
    "            tags[key].add( parent+key )\n",
    "\n",
    "def check_for_unique_tags(jsonFile):\n",
    "    f = open(jsonFile)\n",
    "    tags = defaultdict(set)\n",
    "    for line in iter(f):\n",
    "        #print line\n",
    "        node = json.loads(line)\n",
    "        extract_tags(node, '', tags)\n",
    "    f.close()\n",
    "    #pprint.pprint (dict(tags))\n",
    "    multis = {k: v for k, v in (dict(tags)).items() if len(tags[k])>1}\n",
    "    pprint.pprint (multis)\n",
    "    \n",
    "check_for_unique_tags(filename + '.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except:\n",
    "    return False\n",
    "\n",
    "def isint(value):\n",
    "  try:\n",
    "    int(value)\n",
    "    return True\n",
    "  except:\n",
    "    return False\n",
    "\n",
    "def extract_data_types(node,parent,tags):\n",
    "    for key in node:\n",
    "        location = parent + key\n",
    "        #print key, node[key]\n",
    "        if isinstance (node[key],dict): \n",
    "            #print \"found dict for \", key\n",
    "            extract_data_types(node[key] , location + \".\", tags)\n",
    "        else:\n",
    "            if location not in tags: tags[location] = set()\n",
    "            tags[location].add( get_data_type(node[key]) )\n",
    "\n",
    "def get_data_type(value):\n",
    "    if value == \"\" or value == \"NULL\":\n",
    "        return type(None)\n",
    "    elif type(value) is list:\n",
    "        return type([])\n",
    "    elif isint(value):\n",
    "        return type(int())\n",
    "    elif isfloat(value):\n",
    "        return type(float())\n",
    "    else:\n",
    "        return type(str())\n",
    "\n",
    "def audit_data_types_in_file(jsonFile):\n",
    "    f = open(jsonFile)\n",
    "    tags = defaultdict(set)\n",
    "    for line in iter(f):\n",
    "        #print line\n",
    "        node = json.loads(line)\n",
    "        extract_data_types(node, '', tags)\n",
    "    f.close()\n",
    "    return dict(tags)\n",
    "    \n",
    "data_types = audit_data_types_in_file(filename + '.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Bergen_County_database_ref': set([<type 'int'>]),\n",
      " u'FIXME': set([<type 'str'>]),\n",
      " u'HFCS': set([<type 'str'>]),\n",
      " u'NHS': set([<type 'str'>]),\n",
      " u'NJDOT_SRI': set([<type 'int'>, <type 'str'>]),\n",
      " u'access': set([<type 'str'>]),\n",
      " u'address.city': set([<type 'str'>]),\n",
      " u'address.country': set([<type 'str'>]),\n",
      " u'address.housenumber': set([<type 'int'>, <type 'str'>]),\n",
      " u'address.postcode': set([<type 'int'>]),\n",
      " u'address.state': set([<type 'str'>]),\n",
      " u'address.street': set([<type 'str'>]),\n",
      " u'admin_level': set([<type 'int'>]),\n",
      " u'alt_name': set([<type 'str'>]),\n",
      " u'amenity': set([<type 'str'>]),\n",
      " u'area': set([<type 'str'>]),\n",
      " u'backrest': set([<type 'str'>]),\n",
      " u'barrier': set([<type 'str'>]),\n",
      " u'bench': set([<type 'str'>]),\n",
      " u'bicycle': set([<type 'str'>]),\n",
      " u'boundary': set([<type 'str'>]),\n",
      " u'bridge': set([<type 'str'>]),\n",
      " u'building': set([<type 'str'>]),\n",
      " u'building_data.colour': set([<type 'str'>]),\n",
      " u'building_data.levels': set([<type 'int'>]),\n",
      " u'building_data.material': set([<type 'str'>]),\n",
      " u'building_data.part': set([<type 'str'>]),\n",
      " u'cables': set([<type 'int'>]),\n",
      " u'capacity': set([<type 'int'>]),\n",
      " u'circuits': set([<type 'int'>]),\n",
      " u'covered': set([<type 'str'>]),\n",
      " u'created.changeset': set([<type 'int'>]),\n",
      " u'created.timestamp': set([<type 'str'>]),\n",
      " u'created.uid': set([<type 'int'>]),\n",
      " u'created.user': set([<type 'int'>, <type 'str'>]),\n",
      " u'created.version': set([<type 'int'>]),\n",
      " u'created_by': set([<type 'str'>]),\n",
      " u'crossing': set([<type 'str'>]),\n",
      " u'cuisine': set([<type 'str'>]),\n",
      " u'cutting': set([<type 'str'>]),\n",
      " u'cycleway': set([<type 'str'>]),\n",
      " u'cycleway.left': set([<type 'str'>]),\n",
      " u'denomination': set([<type 'str'>]),\n",
      " u'ele': set([<type 'int'>]),\n",
      " u'electrified': set([<type 'str'>]),\n",
      " u'end_date': set([<type 'str'>]),\n",
      " u'fee': set([<type 'str'>]),\n",
      " u'fixme': set([<type 'str'>]),\n",
      " u'foot': set([<type 'str'>]),\n",
      " u'footway': set([<type 'str'>]),\n",
      " u'frequency': set([<type 'int'>]),\n",
      " u'gauge': set([<type 'int'>]),\n",
      " u'generator.method': set([<type 'str'>]),\n",
      " u'generator.source': set([<type 'str'>]),\n",
      " u'generator.type': set([<type 'str'>]),\n",
      " u'gnis.Class': set([<type 'str'>]),\n",
      " u'gnis.County': set([<type 'str'>]),\n",
      " u'gnis.County_num': set([<type 'int'>]),\n",
      " u'gnis.ST_alpha': set([<type 'str'>]),\n",
      " u'gnis.ST_num': set([<type 'int'>]),\n",
      " u'gnis.county_id': set([<type 'int'>]),\n",
      " u'gnis.county_name': set([<type 'str'>]),\n",
      " u'gnis.created': set([<type 'str'>]),\n",
      " u'gnis.edited': set([<type 'str'>]),\n",
      " u'gnis.feature_id': set([<type 'int'>]),\n",
      " u'gnis.feature_type': set([<type 'str'>]),\n",
      " u'gnis.id': set([<type 'int'>]),\n",
      " u'gnis.import_uuid': set([<type 'str'>]),\n",
      " u'gnis.reviewed': set([<type 'str'>]),\n",
      " u'gnis.state_id': set([<type 'int'>]),\n",
      " u'goods': set([<type 'str'>]),\n",
      " u'height': set([<type 'float'>, <type 'int'>, <type 'str'>]),\n",
      " u'hgv': set([<type 'str'>]),\n",
      " u'hgv_data.national_network': set([<type 'str'>]),\n",
      " u'hgv_data.state_network': set([<type 'str'>]),\n",
      " u'highspeed': set([<type 'str'>]),\n",
      " u'highway': set([<type 'str'>]),\n",
      " u'horse': set([<type 'str'>]),\n",
      " u'hov': set([<type 'str'>]),\n",
      " u'id': set([<type 'int'>]),\n",
      " u'import_uuid': set([<type 'str'>]),\n",
      " u'is_in': set([<type 'str'>]),\n",
      " u'junction': set([<type 'str'>]),\n",
      " u'landuse': set([<type 'str'>]),\n",
      " u'lanes': set([<type 'int'>]),\n",
      " u'lanes_data.both_ways': set([<type 'int'>]),\n",
      " u'lanes_data.forward': set([<type 'int'>]),\n",
      " u'layer': set([<type 'int'>]),\n",
      " u'leisure': set([<type 'str'>]),\n",
      " u'line': set([<type 'str'>]),\n",
      " u'lit': set([<type 'str'>]),\n",
      " u'man_made': set([<type 'str'>]),\n",
      " u'material': set([<type 'str'>]),\n",
      " u'maxspeed': set([<type 'int'>, <type 'str'>]),\n",
      " u'maxspeed_data.goods': set([<type 'str'>]),\n",
      " u'maxspeed_data.hgv': set([<type 'str'>]),\n",
      " u'min_height': set([<type 'int'>]),\n",
      " u'minspeed': set([<type 'str'>]),\n",
      " u'motor_vehicle': set([<type 'str'>]),\n",
      " u'name': set([<type 'str'>]),\n",
      " u'name_1': set([<type 'str'>]),\n",
      " u'name_data.en': set([<type 'str'>]),\n",
      " u'natural': set([<type 'str'>]),\n",
      " u'network': set([<type 'str'>]),\n",
      " u'node_refs': set([<type 'list'>]),\n",
      " u'noref': set([<type 'str'>]),\n",
      " u'note.lanes': set([<type 'str'>]),\n",
      " u'nycdoitt.bin': set([<type 'int'>]),\n",
      " u'office': set([<type 'str'>]),\n",
      " u'old_name': set([<type 'str'>]),\n",
      " u'old_railway_operator': set([<type 'str'>]),\n",
      " u'old_ref': set([<type 'str'>]),\n",
      " u'oneway': set([<type 'int'>, <type 'str'>]),\n",
      " u'opening_hours': set([<type 'str'>]),\n",
      " u'operator': set([<type 'str'>]),\n",
      " u'park_ride': set([<type 'str'>]),\n",
      " u'parking': set([<type 'str'>]),\n",
      " u'place': set([<type 'str'>]),\n",
      " u'pos': set([<type 'list'>]),\n",
      " u'power': set([<type 'str'>]),\n",
      " u'public_transport': set([<type 'str'>]),\n",
      " u'railway': set([<type 'str'>]),\n",
      " u'railway_data.track_ref': set([<type 'int'>]),\n",
      " u'ref': set([<type 'str'>]),\n",
      " u'religion': set([<type 'str'>]),\n",
      " u'roof.colour': set([<type 'str'>]),\n",
      " u'roof.height': set([<type 'int'>]),\n",
      " u'roof.material': set([<type 'str'>]),\n",
      " u'roof.shape': set([<type 'str'>]),\n",
      " u'route': set([<type 'str'>]),\n",
      " u'service': set([<type 'str'>]),\n",
      " u'shelter': set([<type 'str'>]),\n",
      " u'shop': set([<type 'str'>]),\n",
      " u'sidewalk': set([<type 'str'>]),\n",
      " u'sloped_curb': set([<type 'str'>]),\n",
      " u'snowmobile': set([<type 'str'>]),\n",
      " u'source': set([<type 'str'>]),\n",
      " u'source_data.hgv': set([<type 'str'>]),\n",
      " u'source_data.hgv_data.national_network': set([<type 'str'>]),\n",
      " u'source_data.hgv_data.state_network': set([<type 'str'>]),\n",
      " u'source_data.old_ref': set([<type 'str'>]),\n",
      " u'sport': set([<type 'str'>]),\n",
      " u'start_date': set([<type 'int'>]),\n",
      " u'surface': set([<type 'str'>]),\n",
      " u'tiger.cfcc': set([<type 'str'>]),\n",
      " u'tiger.county': set([<type 'str'>]),\n",
      " u'tiger.name_base': set([<type 'str'>]),\n",
      " u'tiger.name_base_1': set([<type 'int'>, <type 'str'>]),\n",
      " u'tiger.name_base_2': set([<type 'str'>]),\n",
      " u'tiger.name_base_3': set([<type 'str'>]),\n",
      " u'tiger.name_direction_prefix': set([<type 'str'>]),\n",
      " u'tiger.name_direction_prefix_1': set([<type 'str'>]),\n",
      " u'tiger.name_direction_suffix': set([<type 'str'>]),\n",
      " u'tiger.name_type': set([<type 'str'>]),\n",
      " u'tiger.name_type_1': set([<type 'str'>]),\n",
      " u'tiger.reviewed': set([<type 'str'>]),\n",
      " u'tiger.separated': set([<type 'str'>]),\n",
      " u'tiger.source': set([<type 'str'>]),\n",
      " u'tiger.tlid': set([<type 'int'>, <type 'str'>]),\n",
      " u'tiger.upload_uuid': set([<type 'str'>]),\n",
      " u'tiger.zip_left': set([<type 'int'>, <type 'str'>]),\n",
      " u'tiger.zip_left_1': set([<type 'int'>]),\n",
      " u'tiger.zip_left_2': set([<type 'int'>]),\n",
      " u'tiger.zip_left_3': set([<type 'int'>]),\n",
      " u'tiger.zip_right': set([<type 'int'>, <type 'str'>]),\n",
      " u'tiger.zip_right_1': set([<type 'int'>]),\n",
      " u'tiger.zip_right_2': set([<type 'int'>]),\n",
      " u'tiger.zip_right_3': set([<type 'int'>]),\n",
      " u'toll': set([<type 'str'>]),\n",
      " u'tracktype': set([<type 'str'>]),\n",
      " u'traffic_signals': set([<type 'str'>]),\n",
      " u'tunnel': set([<type 'str'>]),\n",
      " u'turn.lanes': set([<type 'str'>]),\n",
      " u'turn.lanes_data.both_ways': set([<type 'str'>]),\n",
      " u'turn.lanes_data.forward': set([<type 'str'>]),\n",
      " u'type': set([<type 'str'>]),\n",
      " u'usage': set([<type 'str'>]),\n",
      " u'voltage': set([<type 'int'>]),\n",
      " u'water': set([<type 'str'>]),\n",
      " u'waterway': set([<type 'str'>]),\n",
      " u'website': set([<type 'str'>]),\n",
      " u'wheelchair': set([<type 'str'>]),\n",
      " u'width': set([<type 'int'>]),\n",
      " u'wikipedia': set([<type 'str'>])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pprint.pprint(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'gauge', u'voltage', u'ele', u'roof.height', u'gnis.id', u'Bergen_County_database_ref', u'circuits', u'created.uid', u'gnis.feature_id', u'frequency', u'capacity', u'gnis.County_num', u'lanes_data.both_ways', u'gnis.ST_num', u'width', u'start_date', u'admin_level', u'lanes', u'gnis.state_id', u'layer', u'created.version', u'nycdoitt.bin', u'gnis.county_id', u'cables', u'id', u'lanes_data.forward', u'building_data.levels', u'created.changeset', u'railway_data.track_ref', u'address.postcode', u'min_height']\n"
     ]
    }
   ],
   "source": [
    "def pick_data_type(data_types):\n",
    "    pick_type = {}\n",
    "    for key in data_types:\n",
    "        if  type([]) in data_types[key]:\n",
    "            pick_type [key] = type([])\n",
    "        elif  type(str()) in data_types[key]:\n",
    "            pick_type [key] = type(str())\n",
    "        elif  type(float()) in data_types[key]:\n",
    "            pick_type [key] = type(float())\n",
    "        elif  type(int()) in data_types[key]:\n",
    "            pick_type [key] = type(int())\n",
    "        else:\n",
    "            pick_type [key] =  type(str())\n",
    "    return pick_type\n",
    "\n",
    "data_types = audit_data_types_in_file(filename + '.json')\n",
    "save_as_data_type = pick_data_type(data_types)\n",
    "#pprint.pprint (save_as_data_type)\n",
    "\n",
    "ints = [ key for (key, value) in save_as_data_type.items() if value == type(int()) and not 'zip' in key]\n",
    "print ints\n",
    "#not_ints = [ key for key in ints if key == type(int()) ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "C:\\mongodb24\\mongodb-win32-x86_64-2008plus-2.4.3\\bin>mongoimport -d osm -c sample --file C:\\Users\\Kathleen\\Documents\\udacity\\wrangling\\osm\\sample.osm.json\n",
    "connected to: 127.0.0.1\n",
    "Fri Nov 04 05:35:01.961 check 9 10952\n",
    "Fri Nov 04 05:35:01.963 imported 10952 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('581c649fd123cce95cd02898'),\n",
       " u'created': {u'changeset': u'41015803',\n",
       "  u'timestamp': u'2016-07-25T17:17:46Z',\n",
       "  u'uid': u'326503',\n",
       "  u'user': u'wambag',\n",
       "  u'version': u'4'},\n",
       " u'id': u'26769789',\n",
       " u'pos': [40.6995927, -74.1868914],\n",
       " u'type': u'node'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_db():\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    # 'examples' here is the database name. It will be created if it does not exist.\n",
    "    db = client.osm\n",
    "    return db\n",
    "\n",
    "db = get_db()\n",
    "db.sample.find_one()\n",
    "\n",
    "#db.test.update({field:\"string\"}, {$set:{field:23}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('581c649fd123cce95cd02f40'),\n",
       " u'address': {u'city': u'Brooklyn',\n",
       "  u'housenumber': u'14',\n",
       "  u'postcode': u'11201',\n",
       "  u'street': u'College Place'},\n",
       " u'created': {u'changeset': u'16297856',\n",
       "  u'timestamp': u'2013-05-26T17:49:08Z',\n",
       "  u'uid': u'904598',\n",
       "  u'user': u'SarahHaskins',\n",
       "  u'version': u'1'},\n",
       " u'id': u'2321029592',\n",
       " u'pos': [40.6962445, -73.9943807],\n",
       " u'type': u'node'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.sample.find_one({\"address.postcode\" : { \"$exists\" : True } })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 2, u'_id': u'08816'}, {u'count': 1, u'_id': u'08854'}, {u'count': 3, u'_id': u'10001'}, {u'count': 2, u'_id': u'10002'}, {u'count': 3, u'_id': u'10003'}, {u'count': 1, u'_id': u'10007'}, {u'count': 2, u'_id': u'10009'}, {u'count': 2, u'_id': u'10011'}, {u'count': 2, u'_id': u'10012'}, {u'count': 2, u'_id': u'10013'}, {u'count': 2, u'_id': u'10014'}, {u'count': 2, u'_id': u'10016'}, {u'count': 1, u'_id': u'10018'}, {u'count': 3, u'_id': u'10019'}, {u'count': 2, u'_id': u'10021'}, {u'count': 1, u'_id': u'10022'}, {u'count': 3, u'_id': u'10023'}, {u'count': 3, u'_id': u'10024'}, {u'count': 1, u'_id': u'10025'}, {u'count': 2, u'_id': u'10027'}, {u'count': 1, u'_id': u'10028'}, {u'count': 3, u'_id': u'10029'}, {u'count': 1, u'_id': u'10030'}, {u'count': 1, u'_id': u'10031'}, {u'count': 2, u'_id': u'10032'}, {u'count': 1, u'_id': u'10033'}, {u'count': 1, u'_id': u'10034'}, {u'count': 4, u'_id': u'10035'}, {u'count': 1, u'_id': u'10039'}, {u'count': 3, u'_id': u'10065'}, {u'count': 3, u'_id': u'10128'}, {u'count': 1, u'_id': u'10282'}, {u'count': 7, u'_id': u'10301'}, {u'count': 5, u'_id': u'10302'}, {u'count': 8, u'_id': u'10303'}, {u'count': 8, u'_id': u'10304'}, {u'count': 18, u'_id': u'10305'}, {u'count': 17, u'_id': u'10306'}, {u'count': 6, u'_id': u'10307'}, {u'count': 7, u'_id': u'10308'}, {u'count': 8, u'_id': u'10309'}, {u'count': 5, u'_id': u'10310'}, {u'count': 19, u'_id': u'10312'}, {u'count': 18, u'_id': u'10314'}, {u'count': 3, u'_id': u'10451'}, {u'count': 2, u'_id': u'10452'}, {u'count': 3, u'_id': u'10453'}, {u'count': 3, u'_id': u'10454'}, {u'count': 1, u'_id': u'10455'}, {u'count': 1, u'_id': u'10456'}, {u'count': 5, u'_id': u'10457'}, {u'count': 4, u'_id': u'10458'}, {u'count': 3, u'_id': u'10459'}, {u'count': 3, u'_id': u'10460'}, {u'count': 5, u'_id': u'10461'}, {u'count': 8, u'_id': u'10462'}, {u'count': 3, u'_id': u'10463'}, {u'count': 2, u'_id': u'10464'}, {u'count': 9, u'_id': u'10465'}, {u'count': 12, u'_id': u'10466'}, {u'count': 6, u'_id': u'10467'}, {u'count': 1, u'_id': u'10468'}, {u'count': 11, u'_id': u'10469'}, {u'count': 4, u'_id': u'10470'}, {u'count': 3, u'_id': u'10471'}, {u'count': 3, u'_id': u'10472'}, {u'count': 4, u'_id': u'10473'}, {u'count': 1, u'_id': u'10474'}, {u'count': 3, u'_id': u'10475'}, {u'count': 2, u'_id': u'11001'}, {u'count': 4, u'_id': u'11004'}, {u'count': 1, u'_id': u'11040'}, {u'count': 4, u'_id': u'11101'}, {u'count': 4, u'_id': u'11102'}, {u'count': 5, u'_id': u'11103'}, {u'count': 4, u'_id': u'11104'}, {u'count': 5, u'_id': u'11105'}, {u'count': 4, u'_id': u'11106'}, {u'count': 6, u'_id': u'11201'}, {u'count': 11, u'_id': u'11203'}, {u'count': 11, u'_id': u'11204'}, {u'count': 4, u'_id': u'11205'}, {u'count': 6, u'_id': u'11206'}, {u'count': 6, u'_id': u'11207'}, {u'count': 11, u'_id': u'11208'}, {u'count': 6, u'_id': u'11209'}, {u'count': 6, u'_id': u'11210'}, {u'count': 6, u'_id': u'11211'}, {u'count': 6, u'_id': u'11212'}, {u'count': 8, u'_id': u'11213'}, {u'count': 14, u'_id': u'11214'}, {u'count': 11, u'_id': u'11215'}, {u'count': 4, u'_id': u'11216'}, {u'count': 6, u'_id': u'11217'}, {u'count': 7, u'_id': u'11218'}, {u'count': 13, u'_id': u'11219'}, {u'count': 9, u'_id': u'11220'}, {u'count': 11, u'_id': u'11221'}, {u'count': 6, u'_id': u'11222'}, {u'count': 12, u'_id': u'11223'}, {u'count': 4, u'_id': u'11224'}, {u'count': 4, u'_id': u'11225'}, {u'count': 8, u'_id': u'11226'}, {u'count': 7, u'_id': u'11228'}, {u'count': 15, u'_id': u'11229'}, {u'count': 5, u'_id': u'11230'}, {u'count': 5, u'_id': u'11231'}, {u'count': 3, u'_id': u'11232'}, {u'count': 8, u'_id': u'11233'}, {u'count': 24, u'_id': u'11234'}, {u'count': 8, u'_id': u'11235'}, {u'count': 19, u'_id': u'11236'}, {u'count': 4, u'_id': u'11237'}, {u'count': 7, u'_id': u'11238'}, {u'count': 1, u'_id': u'11249'}, {u'count': 4, u'_id': u'11354'}, {u'count': 8, u'_id': u'11355'}, {u'count': 5, u'_id': u'11356'}, {u'count': 9, u'_id': u'11357'}, {u'count': 3, u'_id': u'11358'}, {u'count': 3, u'_id': u'11360'}, {u'count': 6, u'_id': u'11361'}, {u'count': 5, u'_id': u'11362'}, {u'count': 1, u'_id': u'11363'}, {u'count': 9, u'_id': u'11364'}, {u'count': 3, u'_id': u'11365'}, {u'count': 2, u'_id': u'11366'}, {u'count': 7, u'_id': u'11367'}, {u'count': 11, u'_id': u'11368'}, {u'count': 4, u'_id': u'11369'}, {u'count': 3, u'_id': u'11370'}, {u'count': 4, u'_id': u'11372'}, {u'count': 6, u'_id': u'11373'}, {u'count': 4, u'_id': u'11374'}, {u'count': 8, u'_id': u'11375'}, {u'count': 12, u'_id': u'11377'}, {u'count': 9, u'_id': u'11378'}, {u'count': 9, u'_id': u'11379'}, {u'count': 12, u'_id': u'11385'}, {u'count': 7, u'_id': u'11411'}, {u'count': 12, u'_id': u'11412'}, {u'count': 11, u'_id': u'11413'}, {u'count': 5, u'_id': u'11414'}, {u'count': 1, u'_id': u'11415'}, {u'count': 3, u'_id': u'11416'}, {u'count': 5, u'_id': u'11417'}, {u'count': 5, u'_id': u'11418'}, {u'count': 10, u'_id': u'11419'}, {u'count': 8, u'_id': u'11420'}, {u'count': 5, u'_id': u'11421'}, {u'count': 9, u'_id': u'11422'}, {u'count': 5, u'_id': u'11423'}, {u'count': 4, u'_id': u'11426'}, {u'count': 5, u'_id': u'11427'}, {u'count': 7, u'_id': u'11428'}, {u'count': 4, u'_id': u'11429'}, {u'count': 9, u'_id': u'11432'}, {u'count': 8, u'_id': u'11433'}, {u'count': 14, u'_id': u'11434'}, {u'count': 7, u'_id': u'11435'}, {u'count': 4, u'_id': u'11436'}, {u'count': 1, u'_id': u'115422'}, {u'count': 2, u'_id': u'11560'}, {u'count': 7, u'_id': u'11691'}, {u'count': 2, u'_id': u'11692'}, {u'count': 2, u'_id': u'11693'}, {u'count': 5, u'_id': u'11694'}, {u'count': 3, u'_id': u'11697'}, {u'count': 1, u'_id': u'11801'}]\n"
     ]
    }
   ],
   "source": [
    "def make_zip_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    \n",
    "    #match brasilia time zone and number of tweets > 100\n",
    "    #project to _id, followers, screen_name, tweets\n",
    "    #sort by followers descenging\n",
    "    \n",
    "    pipeline = [ \n",
    "        { \"$match\": { \"address.postcode\" : { \"$exists\" : True } } },\n",
    "        { \"$group\" : { \"_id\": \"$address.postcode\", \"count\" : {\"$sum\" : 1 }}},\n",
    "        { \"$sort\": {\"_id\":1 }} ]\n",
    "        #{ \"$sort\": {\"address.postcode\":-1 }},\n",
    "        #{ \"$limit\" : 1 } ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.sample.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "db = get_db()\n",
    "pipeline = make_zip_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "#import pprint\n",
    "#pprint.pprint(result)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('581c64a1d123cce95cd052a8'),\n",
      " u'address': {u'city': u'East Brunswick',\n",
      "              u'country': u'US',\n",
      "              u'housenumber': u'304',\n",
      "              u'postcode': u'08816',\n",
      "              u'state': u'NJ',\n",
      "              u'street': u'Palombi Court'},\n",
      " u'building': u'terrace',\n",
      " u'building_data': {u'levels': u'2'},\n",
      " u'created': {u'changeset': u'37964404',\n",
      "              u'timestamp': u'2016-03-20T21:29:09Z',\n",
      "              u'uid': u'95246',\n",
      "              u'user': u'holub',\n",
      "              u'version': u'2'},\n",
      " u'id': u'318881070',\n",
      " u'node_refs': [u'3252748371',\n",
      "                u'3252748372',\n",
      "                u'3252748373',\n",
      "                u'3252748374',\n",
      "                u'3252748371'],\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd052f4'),\n",
      " u'address': {u'city': u'East Brunswick',\n",
      "              u'country': u'US',\n",
      "              u'housenumber': u'8',\n",
      "              u'postcode': u'08816',\n",
      "              u'state': u'NJ',\n",
      "              u'street': u'Adams Court'},\n",
      " u'building': u'terrace',\n",
      " u'building_data': {u'levels': u'2'},\n",
      " u'created': {u'changeset': u'38166439',\n",
      "              u'timestamp': u'2016-03-30T13:04:54Z',\n",
      "              u'uid': u'95246',\n",
      "              u'user': u'holub',\n",
      "              u'version': u'3'},\n",
      " u'id': u'404245924',\n",
      " u'node_refs': [u'4065163514',\n",
      "                u'4065163516',\n",
      "                u'4065163521',\n",
      "                u'4065163523',\n",
      "                u'4065163532',\n",
      "                u'4065163530',\n",
      "                u'4065163531',\n",
      "                u'4065163529',\n",
      "                u'4065163514'],\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "res = db.sample.find({\"address.postcode\" : '08816'})\n",
    "for rec in res:\n",
    "    pprint.pprint (rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('581c64a1d123cce95cd04e21'),\n",
      " u'address': {u'housenumber': u'53',\n",
      "              u'postcode': u'08854',\n",
      "              u'street': u'Knightsbridge Road'},\n",
      " u'alt_name': u'www.inetsoft.com',\n",
      " u'building': u'office',\n",
      " u'created': {u'changeset': u'15362374',\n",
      "              u'timestamp': u'2013-03-14T13:27:48Z',\n",
      "              u'uid': u'1267660',\n",
      "              u'user': u'InetSoftTech',\n",
      "              u'version': u'3'},\n",
      " u'id': u'204460662',\n",
      " u'name': u'InetSoft Technology',\n",
      " u'node_refs': [u'2144693655',\n",
      "                u'2144693182',\n",
      "                u'2144693242',\n",
      "                u'2144693723',\n",
      "                u'2144693655'],\n",
      " u'pos': [None, None],\n",
      " u'source': u'Bing',\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(db.sample.find_one({\"address.postcode\" : '08854'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'115422']\n"
     ]
    }
   ],
   "source": [
    "wrong_length = [ rec['_id'] for rec in result if len(rec['_id']) != 5]\n",
    "\n",
    "##for rec in result:\n",
    "##    zip = rec['_id']\n",
    "##    wrong_length.append(zip)\n",
    "\n",
    "print wrong_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('581c64a1d123cce95cd0534e'),\n",
      " u'address': {u'city': u'Glen Cove',\n",
      "              u'country': u'US',\n",
      "              u'housenumber': u'17',\n",
      "              u'postcode': u'115422',\n",
      "              u'state': u'NY',\n",
      "              u'street': u'Ford Street'},\n",
      " u'building': u'house',\n",
      " u'created': {u'changeset': u'42162760',\n",
      "              u'timestamp': u'2016-09-15T02:49:53Z',\n",
      "              u'uid': u'19488',\n",
      "              u'user': u'miluethi',\n",
      "              u'version': u'1'},\n",
      " u'id': u'442516108',\n",
      " u'node_refs': [u'4401968681',\n",
      "                u'4401968682',\n",
      "                u'4401968686',\n",
      "                u'4401968685',\n",
      "                u'4401968681'],\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(db.sample.find_one({\"address.postcode\" : '115422'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539\n",
      "10952\n"
     ]
    }
   ],
   "source": [
    "res = db.sample.find({\"pos\" : None})\n",
    "print res.count()\n",
    "res = db.sample.find()\n",
    "print res.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 8, u'_id': u'NY'}, {u'count': 2, u'_id': u'NJ'}]\n"
     ]
    }
   ],
   "source": [
    "def make_distinct_with_count_pipeline( by_field ):    \n",
    "    pipeline = [ \n",
    "        { \"$match\": { by_field : { \"$exists\" : True } } },\n",
    "        { \"$group\" : { \"_id\": \"$\" + by_field , \"count\" : {\"$sum\" : 1 }}},\n",
    "        { \"$sort\": {\"count\":-1 }} ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.sample.aggregate(pipeline)]\n",
    "\n",
    "def distinct_with_count(field_name):\n",
    "    db = get_db()\n",
    "    pipeline = make_distinct_with_count_pipeline(field_name)\n",
    "    result = aggregate(db, pipeline)\n",
    "    return result\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(result)\n",
    "result = distinct_with_count('address.state')\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': u'address.state'}\n"
     ]
    }
   ],
   "source": [
    "def make_countdistinct_pipeline( by_field ):    \n",
    "    pipeline = [ \n",
    "        { \"$match\": { by_field : { \"$exists\" : True } } },\n",
    "        { \"$group\" : { \"_id\": \"$\" + by_field }},\n",
    "        { \"$group\": { \"_id\": by_field, \"count\" : {\"$sum\" : 1 } } } ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.sample.aggregate(pipeline)]\n",
    "\n",
    "def count_distinct(field_name):\n",
    "    db = get_db()\n",
    "    pipeline = make_countdistinct_pipeline(field_name)\n",
    "    result = aggregate(db, pipeline)\n",
    "    return result[0]\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(result)\n",
    "result = count_distinct('address.state')\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('581c64a1d123cce95cd052a8'),\n",
      " u'address': {u'city': u'East Brunswick',\n",
      "              u'country': u'US',\n",
      "              u'housenumber': u'304',\n",
      "              u'postcode': u'08816',\n",
      "              u'state': u'NJ',\n",
      "              u'street': u'Palombi Court'},\n",
      " u'building': u'terrace',\n",
      " u'building_data': {u'levels': u'2'},\n",
      " u'created': {u'changeset': u'37964404',\n",
      "              u'timestamp': u'2016-03-20T21:29:09Z',\n",
      "              u'uid': u'95246',\n",
      "              u'user': u'holub',\n",
      "              u'version': u'2'},\n",
      " u'id': u'318881070',\n",
      " u'node_refs': [u'3252748371',\n",
      "                u'3252748372',\n",
      "                u'3252748373',\n",
      "                u'3252748374',\n",
      "                u'3252748371'],\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd052f4'),\n",
      " u'address': {u'city': u'East Brunswick',\n",
      "              u'country': u'US',\n",
      "              u'housenumber': u'8',\n",
      "              u'postcode': u'08816',\n",
      "              u'state': u'NJ',\n",
      "              u'street': u'Adams Court'},\n",
      " u'building': u'terrace',\n",
      " u'building_data': {u'levels': u'2'},\n",
      " u'created': {u'changeset': u'38166439',\n",
      "              u'timestamp': u'2016-03-30T13:04:54Z',\n",
      "              u'uid': u'95246',\n",
      "              u'user': u'holub',\n",
      "              u'version': u'3'},\n",
      " u'id': u'404245924',\n",
      " u'node_refs': [u'4065163514',\n",
      "                u'4065163516',\n",
      "                u'4065163521',\n",
      "                u'4065163523',\n",
      "                u'4065163532',\n",
      "                u'4065163530',\n",
      "                u'4065163531',\n",
      "                u'4065163529',\n",
      "                u'4065163514'],\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "res = db.sample.find({\"address.state\" : {\"$exists\": True , \"$ne\": 'NY'}})\n",
    "#print res\n",
    "for rec in res:\n",
    "    pprint.pprint (rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'address.city', u'count': 6}]\n"
     ]
    }
   ],
   "source": [
    "db = get_db()\n",
    "pipeline = make_countdistinct_pipeline('address.city')\n",
    "result = aggregate(db, pipeline)\n",
    "#import pprint\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd04d5d'),\n",
      " u'created': {u'changeset': u'28749348',\n",
      "              u'timestamp': u'2015-02-10T12:37:06Z',\n",
      "              u'uid': u'51722',\n",
      "              u'user': u'Chris Parker',\n",
      "              u'version': u'7'},\n",
      " u'highway': u'residential',\n",
      " u'id': u'5670797',\n",
      " u'name': u'East 82nd Street',\n",
      " u'node_refs': [u'42439389',\n",
      "                u'3341858523',\n",
      "                u'3341917065',\n",
      "                u'42439392',\n",
      "                u'3341917066',\n",
      "                u'3341912573',\n",
      "                u'596776127',\n",
      "                u'42439395',\n",
      "                u'3341912575',\n",
      "                u'42439399',\n",
      "                u'42439403',\n",
      "                u'42439406',\n",
      "                u'42439409',\n",
      "                u'42428027',\n",
      "                u'42439416'],\n",
      " u'oneway': u'yes',\n",
      " u'pos': [None, None],\n",
      " u'tiger': {u'cfcc': u'A41',\n",
      "            u'county': u'New York, NY',\n",
      "            u'name_base': u'82nd',\n",
      "            u'name_direction_prefix': u'E',\n",
      "            u'name_type': u'St',\n",
      "            u'reviewed': u'no',\n",
      "            u'zip_left': u'10028',\n",
      "            u'zip_right': u'10028'},\n",
      " u'type': u'way'}\n",
      "3\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd04eb7'),\n",
      " u'address': {u'housenumber': u'78-74',\n",
      "              u'postcode': u'11385',\n",
      "              u'street': u'82nd Street'},\n",
      " u'building': u'yes',\n",
      " u'created': {u'changeset': u'20385511',\n",
      "              u'timestamp': u'2014-02-05T04:33:39Z',\n",
      "              u'uid': u'1917473',\n",
      "              u'user': u'aaron_nycbuildings',\n",
      "              u'version': u'2'},\n",
      " u'height': u'9.8',\n",
      " u'id': u'247494995',\n",
      " u'node_refs': [u'2543737970',\n",
      "                u'2543738042',\n",
      "                u'2543738055',\n",
      "                u'2543737989',\n",
      "                u'2543737970'],\n",
      " u'nycdoitt': {u'bin': u'4537173'},\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd04f63'),\n",
      " u'address': {u'housenumber': u'252-03',\n",
      "              u'postcode': u'11426',\n",
      "              u'street': u'82nd Drive'},\n",
      " u'building': u'yes',\n",
      " u'created': {u'changeset': u'20784519',\n",
      "              u'timestamp': u'2014-02-26T06:28:49Z',\n",
      "              u'uid': u'1917473',\n",
      "              u'user': u'aaron_nycbuildings',\n",
      "              u'version': u'3'},\n",
      " u'height': u'6.7',\n",
      " u'id': u'248532838',\n",
      " u'node_refs': [u'2553016654',\n",
      "                u'2553016642',\n",
      "                u'2553016656',\n",
      "                u'2553016641',\n",
      "                u'2553016747',\n",
      "                u'2553016771',\n",
      "                u'2553016654'],\n",
      " u'nycdoitt': {u'bin': u'4175089'},\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n",
      "{u'_id': ObjectId('581c64a1d123cce95cd050cb'),\n",
      " u'address': {u'housenumber': u'224',\n",
      "              u'postcode': u'10024',\n",
      "              u'street': u'West 82nd Street'},\n",
      " u'building': u'yes',\n",
      " u'created': {u'changeset': u'21442652',\n",
      "              u'timestamp': u'2014-04-01T16:25:28Z',\n",
      "              u'uid': u'1781294',\n",
      "              u'user': u'Rub21_nycbuildings',\n",
      "              u'version': u'1'},\n",
      " u'height': u'13.7',\n",
      " u'id': u'270899508',\n",
      " u'node_refs': [u'2758620603',\n",
      "                u'2758620616',\n",
      "                u'2758620635',\n",
      "                u'2758620652',\n",
      "                u'2758620728',\n",
      "                u'2758620712',\n",
      "                u'2758620697',\n",
      "                u'2758620693',\n",
      "                u'2758620684',\n",
      "                u'2758620672',\n",
      "                u'2758620662',\n",
      "                u'2758620603'],\n",
      " u'nycdoitt': {u'bin': u'1032693'},\n",
      " u'pos': [None, None],\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "res = db.sample.find({\"$and\":[{\"tiger.name_base\" : {\"$exists\": True }}, \n",
    "                              {\"address.street\": {\"$exists\": True}} ] })\n",
    "print res.count()\n",
    "#for rec in res:\n",
    "#    pprint.pprint (rec)\n",
    "\n",
    "res = db.sample.find_one({\"tiger.name_base\": {\"$exists\": True}})\n",
    "pprint.pprint(res)\n",
    "\n",
    "matchy = db.sample.find({\"address.street\": {\"$regex\" : \"82\"} })\n",
    "print matchy.count()\n",
    "for rec in matchy: pprint.pprint (rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger # 153\n",
      "maybe match # 48\n",
      "no match # 101\n"
     ]
    }
   ],
   "source": [
    "def cross_check_ways ():\n",
    "    no_match = {}\n",
    "    maybe_match = {}\n",
    "    res = db.sample.find({\"tiger.name_base\": {\"$exists\": True}})\n",
    "    print \"tiger #\", res.count()\n",
    "    for rec in res:\n",
    "        name = rec[\"tiger\"][\"name_base\"]\n",
    "        matchy = db.sample.find({\"address.street\": {\"$regex\" : name} })\n",
    "        if matchy.count()>0: \n",
    "            if name not in maybe_match: \n",
    "                maybe_match[name] = [a for a in matchy]\n",
    "            maybe_match[name].insert(0,rec)\n",
    "        else: no_match[name] = rec\n",
    "            \n",
    "    print \"maybe match #\", len(maybe_match)\n",
    "    print \"no match #\", len(no_match)\n",
    "    return maybe_match, no_match\n",
    "\n",
    "(maybe_match, no_match) = cross_check_ways()\n",
    "#pprint.pprint(maybe_match[maybe_match.keys()[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****   82nd   *****\n",
      "E 82nd St (tiger)\n",
      "82nd St (tiger)\n",
      "82nd Street (address)\n",
      "82nd Drive (address)\n",
      "West 82nd Street (address)\n",
      "*****   56th   *****\n",
      "56th Ave (tiger)\n",
      "East 156th Street (address)\n",
      "256th Street (address)\n",
      "156th Street (address)\n"
     ]
    }
   ],
   "source": [
    "for street in maybe_match.keys() [:2]:\n",
    "    print '*****  ' , street, '  *****'\n",
    "    for rec in maybe_match[street]:\n",
    "        try: \n",
    "            x = rec['address']['street'] + ' ' + '(address)'\n",
    "            print x\n",
    "        except: pass\n",
    "        try:\n",
    "            x = rec['tiger']['name_direction_prefix']+ ' ' + rec['tiger']['name_base']+ ' ' +  rec['tiger']['name_type']+ ' ' +  '(tiger)'\n",
    "            print x\n",
    "        except: pass\n",
    "        try:\n",
    "            x = rec['tiger']['name_base']+ ' ' +  rec['tiger']['name_type']+ ' ' +  '(tiger)'\n",
    "            print x\n",
    "        except: pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10952\n"
     ]
    }
   ],
   "source": [
    "size = db.sample.count()\n",
    "print size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'type', u'count': 2}\n"
     ]
    }
   ],
   "source": [
    "types = count_distinct(\"type\")\n",
    "pprint.pprint(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct  created.user created.user  - count 377\n",
      "Distinct  address.postcode address.postcode  - count 169\n",
      "Distinct  address.city address.city  - count 6\n",
      "Distinct  amenity amenity  - count 14\n",
      "Distinct  source source  - count 13\n"
     ]
    }
   ],
   "source": [
    "def print_count_distincts(fields):\n",
    "    for field_name in fields:\n",
    "        #pprint.pprint(get_top(field_name))\n",
    "        count_dist = count_distinct(field_name)\n",
    "        print \"Distinct \", field_name, count_dist['_id'], ' - count', count_dist['count']\n",
    "\n",
    "get_count_distincts_fields = ['created.user', 'address.postcode', 'address.city', 'amenity','source']\n",
    "print_count_distincts(get_count_distincts_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top created.user Rub21_nycbuildings  - count 4923\n",
      "Top address.postcode 11234  - count 24\n",
      "Top address.city New York  - count 4\n",
      "Top amenity parking  - count 10\n",
      "Top source Bing  - count 6\n"
     ]
    }
   ],
   "source": [
    "def make_get_top_pipeline( by_field ):    \n",
    "    pipeline = [ \n",
    "        { \"$match\": { by_field : { \"$exists\" : True } } },\n",
    "        { \"$group\" : { \"_id\": \"$\" + by_field , \"count\" : {\"$sum\" : 1 }}},\n",
    "        { \"$sort\": { \"count\" :-1 }},\n",
    "        { \"$limit\" : 1 } ]\n",
    "    return pipeline\n",
    "\n",
    "def get_top(field_name):\n",
    "    db = get_db()\n",
    "    pipeline = make_get_top_pipeline(field_name)\n",
    "    result = aggregate(db, pipeline)\n",
    "    return result[0]\n",
    "\n",
    "def print_tops(fields):\n",
    "    for field_name in fields:\n",
    "        #pprint.pprint(get_top(field_name))\n",
    "        top = get_top(field_name)\n",
    "        print \"Top\", field_name, top['_id'], ' - count', top['count']\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(result)\n",
    "get_top_fields = ['created.user', 'address.postcode', 'address.city', 'amenity','source']\n",
    "print_tops(get_top_fields)\n",
    "\n",
    "\n",
    "#([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":­1}}, {\"$limit\":1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'french', u'count': 1},\n",
       " {u'_id': u'japanese', u'count': 1},\n",
       " {u'_id': u'burger', u'count': 1}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_with_count(\"cuisine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'Bing', u'count': 6},\n",
       " {u'_id': u'NJ2002LULC', u'count': 5},\n",
       " {u'_id': {u'hgv_data': {u'state_network': u'NJDOT http://www.state.nj.us/transportation/about/rules/pdf/chapter32truckaccess.pdf'}},\n",
       "  u'count': 5},\n",
       " {u'_id': u'USGS Geonames', u'count': 3},\n",
       " {u'_id': u'TIGER/Line\\xae 2008 Place Shapefiles (http://www.census.gov/geo/www/tiger/)',\n",
       "  u'count': 2},\n",
       " {u'_id': {u'hgv': u'Rules of the City of New York Title 34 \\xa74-13 http://24.97.137.100/nyc/rcny/Title34_4-13.asp'},\n",
       "  u'count': 2},\n",
       " {u'_id': {u'hgv_data': {u'national_network': u'NJDOT http://www.state.nj.us/transportation/about/rules/pdf/chapter32truckaccess.pdf'}},\n",
       "  u'count': 2},\n",
       " {u'_id': u'BingSat, site review in August 2016 and mapillary imagery',\n",
       "  u'count': 1},\n",
       " {u'_id': {u'old_ref': u'1947 and 1951 maps http://mapmaker.rutgers.edu/MIDDLESEX_COUNTY/MiddlesexCounty.html'},\n",
       "  u'count': 1},\n",
       " {u'_id': u'Local Knowladge', u'count': 1},\n",
       " {u'_id': u'bing', u'count': 1},\n",
       " {u'_id': u'survey', u'count': 1},\n",
       " {u'_id': u'tiger_import_dch_v0.6_20070829', u'count': 1}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_with_count(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct cuisine\n",
      "[{u'_id': u'french', u'count': 1},\n",
      " {u'_id': u'japanese', u'count': 1},\n",
      " {u'_id': u'burger', u'count': 1}]\n",
      " \n",
      "Distinct source\n",
      "[{u'_id': u'Bing', u'count': 6},\n",
      " {u'_id': u'NJ2002LULC', u'count': 5},\n",
      " {u'_id': {u'hgv_data': {u'state_network': u'NJDOT http://www.state.nj.us/transportation/about/rules/pdf/chapter32truckaccess.pdf'}},\n",
      "  u'count': 5},\n",
      " {u'_id': u'USGS Geonames', u'count': 3},\n",
      " {u'_id': u'TIGER/Line\\xae 2008 Place Shapefiles (http://www.census.gov/geo/www/tiger/)',\n",
      "  u'count': 2},\n",
      " {u'_id': {u'hgv': u'Rules of the City of New York Title 34 \\xa74-13 http://24.97.137.100/nyc/rcny/Title34_4-13.asp'},\n",
      "  u'count': 2},\n",
      " {u'_id': {u'hgv_data': {u'national_network': u'NJDOT http://www.state.nj.us/transportation/about/rules/pdf/chapter32truckaccess.pdf'}},\n",
      "  u'count': 2},\n",
      " {u'_id': u'BingSat, site review in August 2016 and mapillary imagery',\n",
      "  u'count': 1},\n",
      " {u'_id': {u'old_ref': u'1947 and 1951 maps http://mapmaker.rutgers.edu/MIDDLESEX_COUNTY/MiddlesexCounty.html'},\n",
      "  u'count': 1},\n",
      " {u'_id': u'Local Knowladge', u'count': 1},\n",
      " {u'_id': u'bing', u'count': 1},\n",
      " {u'_id': u'survey', u'count': 1},\n",
      " {u'_id': u'tiger_import_dch_v0.6_20070829', u'count': 1}]\n",
      " \n",
      "Distinct leisure\n",
      "[{u'_id': u'pitch', u'count': 5},\n",
      " {u'_id': u'park', u'count': 5},\n",
      " {u'_id': u'playground', u'count': 2},\n",
      " {u'_id': u'swimming_pool', u'count': 1},\n",
      " {u'_id': u'sports_centre', u'count': 1},\n",
      " {u'_id': u'miniature_golf', u'count': 1}]\n",
      " \n",
      "Distinct office\n",
      "[{u'_id': u'financial', u'count': 1}]\n",
      " \n",
      "Distinct service\n",
      "[{u'_id': u'parking_aisle', u'count': 7},\n",
      " {u'_id': u'yard', u'count': 7},\n",
      " {u'_id': u'driveway', u'count': 2}]\n",
      " \n",
      "Distinct shelter\n",
      "[{u'_id': u'yes', u'count': 1}, {u'_id': u'no', u'count': 1}]\n",
      " \n",
      "Distinct shop\n",
      "[{u'_id': u'supermarket', u'count': 2},\n",
      " {u'_id': u'kiosk', u'count': 1},\n",
      " {u'_id': u'car', u'count': 1},\n",
      " {u'_id': u'laundry', u'count': 1}]\n",
      " \n",
      "Distinct sport\n",
      "[{u'_id': u'tennis', u'count': 3},\n",
      " {u'_id': u'american_football', u'count': 1},\n",
      " {u'_id': u'baseball', u'count': 1},\n",
      " {u'_id': u'basketball', u'count': 1}]\n",
      " \n",
      "Distinct gnis.feature_type\n",
      "[{u'_id': u'Bay', u'count': 1}]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "get_distincts = [\"cuisine\", \"source\", \"leisure\", \"office\", \"service\", \"shelter\", \"shop\", \"sport\", \"gnis.feature_type\"]\n",
    "\n",
    "for field_name in get_distincts:\n",
    "    print \"Distinct\", field_name\n",
    "    pprint.pprint (distinct_with_count(field_name))\n",
    "    print \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
